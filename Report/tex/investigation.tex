\section{Previous Work}
\label{sec:PW}
While investigating possible solutions on how to automatically transcribe beatboxing, many articles, books and papers on the topic have been investigated. Three specific articles were found to be of utmost importance to the project, which addresses relevant topics, i.e. transcription and sound classification of beatboxing. Below are reviews of the three mentioned articles.

\subsection{Towards Automatic Transcription of Expressive Oral Percussive Performances}
In this article Amoury Hazan \cite{Hazan2005} proposes a solution to automatic transcription that involves sound segmentation, oral percussive descriptors, and machine learning techniques. Sound segmentation is described as a simple method that fits well with monophonic oral percussive recordings, which requires few computing resources.	

His project aims to reduce the gap between the user and the device (keyboard, drum pad), among other things in order to aid those musicians who cannot transcript a beat they have on their mind.
Through research of the taxonomy of human phonemes, and assuring perfect percussive events through segmentation and transcription, the resulting drum score lack information concerning how the performer has modulated the produced sound. Thus, Hazan argues that energy and resonance frequency variation have to be defined together with effective computational methods to track them.

The considerations made by Hazan may serve as a benchmark tool which may suffice to serve as a possible solution to the problem. The technical descriptions and reflections could serve as an inspiration regarding how to construct the software based transcription-solution.

\subsection{Beatbox Classification Using ACE}
Elliot Sinyor et al. \cite{Sinyor05} have made a system that classifies the different beatboxing inputs. In the test they used three skilled beatboxers, and three amateurs. Sinyor et al. \cite{Sinyor05} tested different features to investigate which gave the best classification performance. 


The beatboxers and non-beatboxers were told to imitate four different types of sounds: kick drum, snare drum, closed hi-hat and open hi-hat. However because some of the participants imitated the snare in different ways, both as a k- and p-snare, they ended up with 5 types of sounds.

The features used for classification were: Zero-Crossing, Zero-Crossing Rate, Compactness, Spectral Centroid, Spectral Flux, Spectral Rolloff and Root Mean Square \citep{Sinyor05}.


In the second test Sinyor et al. \cite{Sinyor05} used a k-NN coupled with a Genetic Algorithm to select the most effective features for beatboxing sound classification. The features selected were namely: Zero-Crossing (rate), Root Mean Square, Spectral Rolloff, Compactness.


The best results were when they used all of the five classes, where the k-NN classifier had an accuracy of 94.55\%. The best result with only three sound classes (kick, snare, hihat) was with the k-NN classifier and had an accuracy rate of 98.55\% 
When looking at the results the accuracy was pretty high, and the highest percentage was with few sound classes (three), where they used the k-NN classifier. 

This article is relevant since the system possibly can be used in the future for voice-controlled applications.

\subsection{Delayed decision-making in real-time beatbox percussion classification}
In \textit{Delayed decision-making in real-time beatbox percussion classification} Dan Stowell and Mark D. Plumbey study the relationship and balance between low-latency and high precision in a real-time classification system of beatboxing sounds. Their hypothesis is that the performance of a real-time classifier will improve if its final decision is allowed to be delayed. 
In order to do this they propose a solution in which an event trigger occurs before the classification, which allows the system to have an initial decision before its final classification. One aspect of the study is the performance of classification, but another aspect they investigate is the perception of the listening experience and quality of the audio output.


Using Sonic Visualiser, onsets of kick, snare and hi-hat sounds has been manually annotated in 14 short recordings of beatboxing (performed by both amateurs and semi-pros) by listening and inspecting sonograms and waveforms. The recordings are then used to test the performance of a three-way classification (kick, snare and hihat), and is measured through Kullback-Leibler divergence and the Na√Øve Bayes classifier independently on 24 different acoustic features including: eight MFCCs, Spectral Spread, Spectral Centroid, Spectral Crest Factor, four subbands to Spectral Crest Factor, Spectral Roll-Off (25\%, 50\%, 80\%, 95\%), High-Frequency Content, Zero-Crossing Rate, Spectral Flatness, Spectral Flux, Spectral Slope.


The classification experiments tested on the performance of high precision classification when its decision is delayed.
The delay is defined in frames in relation to the onset, and the results of the classification experiments show that in general for all of the features a delay of 2 frames (approximately 23 ms) gave the strongest classification performance.
The perceptual experiments were performed using MUSHRA \footnote{MUSHRA-LINK} to understand how the delayed decision-making affects the listening experience of the audio output, which could be important in e.g. real-time musical performances. The experiments were performed with 3 kinds of drum sets: Immediate-Onset samples, Roland TR-909 samples and Amen Break samples. Delay frames from 1-4 (12, 23, 35 and 46 ms) were investigated, where each sound excerpt also had a reference signal (of 8 seconds) and a low quality anchor. The results show that regarding the Immediate Onset drum set, the delayed decision-making were unacceptable at any delay. For the two remaining drum sets the accepted delays varied between 12-35 ms.


Altogether the delayed decision-making was acceptable in some cases, but since they used pre-made sound excerpts with 100 \% classification accuracy (after the delay), to focus only on the perceptual listening experience, the overall experience might have been different if it was used in real-time during a live beatbox performance. 
The confusion matrix of classifications with a delay of 2 frames show that the snare sounds often (31.5\%) were misclassified as a kick sound. Stowell and Plumbey suggest that it might be because they are produced in a similar way with plosive sounds. \\
Annotations through Sonic Visualiser, SBN and some of the features used in the classification will be important and relevant to explore for this project.