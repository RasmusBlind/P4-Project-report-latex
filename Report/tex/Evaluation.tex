% Chapter 'Evaluation'
In this chapter we will evaluate the performance of our transcription system. bla bla

\section{Methods}

	\subsection{Training and Test Sets}
		The dataset consists of sound segments, segmented based on the annotations. This means that our segmentation of sound (present in our application), will not be part of the evaluation.
		The training and test sets of sounds for the KNN classifier are randomly chosen from the same pool (the dataset). It is distributed between the training and test set in a 70\%/30\% ratio, accordingly, for each class. This means there will not be a fixed number of sounds for each class (neither total nor divided), but rather a fixed distribution between the number of training and test sounds for each class. We can do this instead of e.g. k-fold cross validation, due to scale of our collected dataset. The ratio was suggested by our supervisor\footnote{Bob L. Sturm}. Furthermore, all sounds with a duration less than the windowsize used for feature calculation, are removed before testing. This is done before splitting the dataset, such as to make sure we do not distort the 70/30 distribution.

		\begin{table}
			\centering
			\begin{tabular}{|l|r|r|}
				\hline
				Value  &  Count  & Percent \\ \hline
		      noise    &  150    & 10.19\% \\ \hline
		          k    &  466    & 31.66\% \\ \hline
		  undefined    &  130    &  8.83\% \\ \hline
		          s    &  331    & 22.49\% \\ \hline
		         hh    &  395    & 26.83\% \\ \hline
		      TOTAL    &  1472	 & 100.00\% \\ \hline

			\end{tabular}
			\caption{Dataset composition}
		\end{table}

		maybe some more

	\subsection{Variables}
		As the number of combinations of features, and parameters of features and classifiers, is very large, we purposely keep as few variables as possible. We chose not to test combinations of features, but rather single features one at a time.
		The primary variable to be tested is the K in the KNN classifier (how many neighbors it considers). Beyond that, we only try a couple of changes to the feature parameter such as windowsizes, windowskip sized, and so forth. This 

	\subsection{Measures}
		A confusion table is created for each test (each unique combination of variables). This will be shown in percentages (or rather, values between 0 and 1). Overall accuracy is calculated, along with precision, recall, and F-score for each class individually.

		chi squared?
		sign test?

 
\section{Results}

	\subsection{MFCC}

		\begin{table}
			\begin{subtable}[h]{0.45\textwidth}
				\centering
				\begin{tabular}{|c | c | c | c | c |}
					\hline
					   & k & s & hh\\ \hline
					k  & 0.986 & 0.020 & 0.009\\ \hline
					s  & 0.007 & 0.899 & 0.025\\ \hline
					hh & 0.007 & 0.081 & 0.966\\ \hline
				\end{tabular}
				\caption{$K=1$}
				\label{table:mfcc:k1}
			\end{subtable}
			\hfill
			\begin{subtable}[h]{0.45\textwidth}
				\centering
				\begin{tabular}{|c | c | c | c | c |}
					\hline
					   & k & s & hh\\ \hline
					k  & 0.986 & 0.020 & 0.009\\ \hline
					s  & 0.007 & 0.899 & 0.025\\ \hline
					hh & 0.007 & 0.081 & 0.966\\ \hline
				\end{tabular}
				\caption{$K=1$}
				\label{table:mfcc:k1}
			\end{subtable}
			\caption{MFCC with K=1}
			\label{mfcck1}
		\end{table}